{
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Lab assignment â„–1, part 2\n\nThis lab assignment consists of several parts. You are supposed to make some transformations, train some models, estimate the quality of the models and explain your results.\n\nSeveral comments:\n* Don't hesitate to ask questions, it's a good practice.\n* No private/public sharing, please. The copied assignments will be graded with 0 points.\n* Blocks of this lab will be graded separately.",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-86e0de040aac317a",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "__*This is the second part of the assignment. First and third parts are waiting for you in the same directory.*__",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Part 2. Data preprocessing, model training and evaluation.",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-512ba712fc0fc065",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 1. Reading the data\nToday we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below.",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b656a4266174b009",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# If on colab, uncomment the following lines\n\n# ! wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_made/homeworks/lab01_ml_pipeline/car_data.csv",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\ndataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\ndata = dataset[:, :-1].astype(int)\ntarget = dataset[:, -1]\n\nprint(data.shape, target.shape)\n\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-eebac6bfdf73d0bc",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below.",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-88b1a0f688568f2c",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "X_train_pd = pd.DataFrame(X_train)\n\n# First 15 rows of our dataset.\nX_train_pd.head(15)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Methods `describe` and `info` deliver some useful information.",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-98e7d91d77d65fcf",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "X_train_pd.describe()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X_train_pd.info()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### 2. Machine Learning pipeline\nHere you are supposed to perform the desired transformations. Please, explain your results briefly after each task.",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-be844269be69c387",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.0. Data preprocessing\n* Make some transformations of the dataset (if necessary). Briefly explain the transformations",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "### YOUR CODE HERE\n# Here we perform some normalizing and centring of our our data. We normalize both test and train data\n# Actually, we norm test data by train one, because we suppose that test data is unreachable for us at this moment, but not to forget about normolizing later\n\nX_train_norm = (X_train - np.mean(X_train,axis = 0))/np.std(X_train,axis = 0) #centering and normilize train data\nX_test_norm = (X_test - np.mean(X_train,axis = 0))/np.std(X_train,axis = 0) #centering and normilize test data\n",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-a1514aa189a49fca",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.1. Basic logistic regression\n* Find optimal hyperparameters for logistic regression with cross-validation on the `train` data (small grid/random search is enough, no need to find the *best* parameters).\n\n* Estimate the model quality with `f1` and `accuracy` scores.\n* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n\n*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` `tol=1e-3` and ` max_iter=500`.*",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "### YOUR CODE HERE\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nmodel = LogisticRegressionCV(cv = 9,multi_class='multinomial', solver='saga', tol=1e-3, max_iter=500)\nmodel.fit(X_train_norm, y_train)\ny_pred = model.predict(X_test_norm)\n# print(y_pred)\nprint(accuracy_score(y_test, y_pred))\nprint(f1_score(y_test, y_pred,average='micro'))",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-1dd5ad5d0845cbbb",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# You might use this command to install scikit-plot. \n# Warning, if you a running locally, don't call pip from within jupyter, call it from terminal in the corresponding \n# virtual environment instead\n\n# ! pip install scikit-plot",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.2. PCA: explained variance plot\n* Apply the PCA to the train part of the data. Build the explaided variance plot. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "### YOUR CODE HERE\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\npipe_pca = Pipeline([('standart', StandardScaler()), ('pca', PCA())])\n\npipe_pca.fit(X_train)\nprint(pipe_pca['pca'].explained_variance_ratio_)\nx = np.linspace(1,19,19)\ny =pipe_pca['pca'].explained_variance_ratio_\nplt.plot(x,y)\nplt.scatter(x, y)\nplt.ylabel(\"variance_ratio\")\nplt.xlabel(\"number of feature\")",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-c6c614740bce090e",
          "locked": false,
          "points": 10,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.3. PCA trasformation\n* Select the appropriate number of components. Briefly explain your choice. Should you normalize the data?\n\n*Use `fit` and `transform` methods to transform the `train` and `test` parts.*",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0c1fe666f52fe53c",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "### YOUR CODE HERE\n### Here we manage some PCA transformation. Our data is already normalized\nfrom sklearn.decomposition import PCA\nimport numpy as np\npca = PCA(n_components = 15)\npca.fit(X_train_norm)\nX_train_new = pca.transform(X_train_norm)\nX_test_new = pca.transform(X_test_norm)\n# pca.transform(X_train_norm)\n# pca.transform(X_test_norm).shape",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-96ab18d96473ef71",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**Note: From this point `sklearn` [Pipeline](https://scikit-learn.org/stable/modules/compose.html) might be useful to perform transformations on the data. Refer to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more information.**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.4. Logistic regression on PCA-preprocessed data.\n* Find optimal hyperparameters for logistic regression with cross-validation on the transformed by PCA `train` data.\n\n* Estimate the model quality with `f1` and `accuracy` scores.\n* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n\n*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` and `tol=1e-3`*",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d28b58a35c94e988",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "### YOUR CODE HERE\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.model_selection import GridSearchCV\npipe = Pipeline([('standart', StandardScaler()), ('pca', PCA(n_components=13)), ('logreg', LogisticRegression(multi_class='multinomial',solver='saga',tol=1e-3))])\nparam_grid = dict(logreg__C=[0.01, 0.1, 1, 5, 10, 100])\ngrid_search = GridSearchCV(pipe, param_grid, refit=True)\ngrid_search.fit(X_train, y_train)",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-12d53ea45258fa82",
          "locked": false,
          "points": 5,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.5. Decision tree\n* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation.\n\n* Measure the model quality using the same metrics you used above.",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4fbf16c64076e139",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\n# YOUR CODE HERE\ntree = DecisionTreeClassifier(max_depth = 15)\ntree.fit(X_train_norm, y_train)\ny_pred = tree.predict(X_test_norm)\nprint(accuracy_score(y_test, y_pred))\nprint(f1_score(y_test, y_pred,average='micro'))",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-748ed20b51c67fab",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.6. Bagging.\nHere starts the ensembling part.\n\nFirst we will use the __Bagging__ approach. Build an ensemble of $N$ algorithms varying N from $N_{min}=2$ to $N_{max}=100$ (with step 5).\n\nWe will build two ensembles: of logistic regressions and of decision trees.\n\n*Comment: each ensemble should be constructed from models of the same family, so logistic regressions should not be mixed up with decision trees.*\n\n\n*Hint 1: To build a __Bagging__ ensebmle varying the ensemble size efficiently you might generate $N_{max}$ subsets of `train` data (of the same size as the original dataset) using bootstrap procedure once. Then you train a new instance of logistic regression/decision tree with optimal hyperparameters you estimated before on each subset (so you train it from scratch). Finally, to get an ensemble of $N$ models you average the $N$ out of $N_{max}$ models predictions.*\n\n*Hint 2: sklearn might help you with this taks. Some appropriate function/class might be out there.*\n\n* Plot `f1` and `accuracy` scores plots w.r.t. the size of the ensemble.\n\n* Briefly analyse the plot. What is the optimal number of algorithms? Explain your answer.\n\n* How do you think, are the hyperparameters for the decision trees you found in 2.5 optimal for trees used in ensemble? ",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9eadd4d8a03ae67a",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# YOUR CODE HERE\nfrom sklearn.ensemble import BaggingClassifier\n\nn_s = [i for i in range(2,100,5)]\nlog_bags = []\ntree_bags = []\nfor n in n_s:\n  log_bag = BaggingClassifier(base_estimator=model, n_estimators=2).fit(X_train_new, y_train)\n  tree_bag = BaggingClassifier(base_estimator=tree, n_estimators=10).fit(X_train_new, y_train)\n  # y_pred_log= log_bag.predict(X_test_new)\n  # y_pred_tree = tree_bag.predict(X_test_new)\n  # print(accuracy_score(y_test, y_pred_log), accuracy_score(y_test, y_pred_tree))\n  # print(f1_score(y_test, y_pred_log,average='micro'), f1_score(y_test, y_pred_tree,average='micro'))\n  log_bags.append(log_bag)\n  tree_bags.append(tree_bag)",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-8fc95a2b206bdae1",
          "locked": false,
          "points": 35,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\naccuracies_log = [accuracy_score(log_bags[i].predict(X_test_new), y_test) for i in range(20)]\naccuracies_tree = [accuracy_score(tree_bags[i].predict(X_test_new), y_test) for i in range(20)]\nf1_log = [f1_score(log_bags[i].predict(X_test_new), y_test,average='micro') for i in range(20)]\nf1_tree = [f1_score(tree_bags[i].predict(X_test_new), y_test,average='micro') for i in range(20)]\nplt.plot(n_s,accuracies_log, label=\"accuracies_log\")\nplt.plot(n_s, accuracies_tree, label=\"accuracies_tree\")\n# plt.plot(range(20),f1_log,label = \"f1_log\")\n# plt.plot(range(20),f1_tree, label =\"f1_tree\")\nplt.legend()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.7. Random Forest\nNow we will work with the Random Forest (its `sklearn` implementation).\n\n* * Plot `f1` and `accuracy` scores plots w.r.t. the number of trees in Random Forest.\n\n* What is the optimal number of trees you've got? Is it different from the optimal number of logistic regressions/decision trees in 2.6? Explain the results briefly.",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-241b7691ab44cbfb",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\n# YOUR CODE HERE\nn_s = [i for i in range(1,550,5)]\nrand_forests = [RandomForestClassifier(n).fit(X_train_new, y_train) for n in n_s]\naccuracies = [accuracy_score(rand_forests[i].predict(X_test_new), y_test) for i in range(len(n_s))]\nf1 = [f1_score(rand_forests[i].predict(X_test_new), y_test,average='micro') for i in range(len(n_s))]\nplt.plot(n_s,accuracies, label=\"accuracies\")\nplt.plot(n_s, f1, label=\"f1\")\nplt.legend()",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-888755d0f3d91620",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 2.8. Learning curve\nYour goal is to estimate, how does the model behaviour change with the increase of the `train` dataset size.\n\n* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n\n* Build a plot of `accuracy` and `f1` scores on `test` part, varying the `train` dataset size (so the axes will be score - dataset size.\n\n* Analyse the final plot. Can you make any conlusions using it? ",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-99191c0852538d4d",
          "locked": true,
          "schema_version": 2,
          "solution": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# YOUR CODE HERE\nx = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\nplt.plot(x, accuracy_tree)\nplt.scatter(x, accuracy_tree)\nplt.title(\"accuracy_score_tree\")\nplt.xlabel(\"X_part\")\nplt.grid(True)\nplt.show()\n\nplt.plot(x, f1_tree)\nplt.scatter(x, f1_tree)\nplt.title(\"f1_score_tree\")\nplt.xlabel(\"X_part\")\nplt.grid(True)\nplt.show()\n\nplt.plot(x, accuracy_logreg)\nplt.scatter(x, accuracy_logreg)\nplt.title(\"accuracy_score_logreg\")\nplt.xlabel(\"X_part\")\nplt.grid(True)\nplt.show()\n\nplt.plot(x, f1_logreg)\nplt.scatter(x, f1_logreg)\nplt.title(\"f1_score_logreg\")\nplt.xlabel(\"X_part\")\nplt.grid(True)\nplt.show()\n\nplt.plot(x, accuracy_forest)\nplt.scatter(x, accuracy_forest)\nplt.title(\"accuracy_score_forest\")\nplt.xlabel(\"X_part\")\nplt.grid(True)\nplt.show()\n\nplt.plot(x, f1_forest)\nplt.scatter(x, f1_forest)\nplt.title(\"f1_score_forest\")\nplt.xlabel(\"X_part\")\nplt.grid(True)\nplt.show()",
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-e39bc7e7dff61ff9",
          "locked": false,
          "points": 15,
          "schema_version": 2,
          "solution": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}